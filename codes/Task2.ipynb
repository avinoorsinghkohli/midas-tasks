{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Task2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFeaX4CuGRyl",
        "outputId": "c20427b3-f72c-4f45-8367-6e15a4903812"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEekNsNFaIhG"
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import time\n",
        "from PIL import Image,ImageOps\n",
        "from keras.datasets import mnist\n",
        "\n",
        "from keras import layers\n",
        "import keras\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.utils import to_categorical\n",
        "from keras import initializers\n",
        "from keras import optimizers\n",
        "from matplotlib import pyplot\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from array import array\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpfk9cB_aIhI",
        "outputId": "e2d16590-672b-40b7-988d-4435704aa020"
      },
      "source": [
        "# if input image is in range 0..1, please first multiply img by 255\n",
        "# assume image is ndarray of shape [height, width, channels] where channels can be 1, 3 or 4\n",
        "# get the train, val and test data   \n",
        "(train_imagesall, train_labels), (test_imagesall, test_labels) = mnist.load_data()\n",
        "\n",
        "#adding the new dimension for conversion of grayscale to rgb\n",
        "train_imagesall=train_imagesall[:,:,:,np.newaxis]\n",
        "test_imagesall=test_imagesall[:,:,:,np.newaxis]\n",
        "train_images=([])\n",
        "test_images1=([])\n",
        "\n",
        "#stacking of the layer vertically about axis =2\n",
        "for i in range(0,60000):\n",
        "  #print(a.shape)\n",
        "  train_images.append(np.concatenate((train_imagesall[i],train_imagesall[i],train_imagesall[i]),axis=2))\n",
        "for i in range(0,10000):\n",
        "  test_images1.append(np.concatenate((test_imagesall[i],test_imagesall[i],test_imagesall[i]),axis=2))\n",
        "\n",
        "train_images=np.array(train_images)\n",
        "test_images1=np.array(test_images1)\n",
        "\n",
        "# train_images=train_imagesall.reshape(60000,28,28,1)\n",
        "# test_images1=test_imagesall.reshape(10000,28,28,1)\n",
        "\n",
        "val_images = test_images1[0:2000,:,:]\n",
        "val_labels = test_labels[0:2000]\n",
        "test_images = test_images1[2000:,:,:]\n",
        "test_labels = test_labels[2000:]\n",
        "\n",
        "\n",
        "# display sample\n",
        "im = train_images[10,:,:]\n",
        "#plt.imshow(im)\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQb9IoEqaIhJ",
        "outputId": "d18aa895-cc6f-4cc1-e3bc-31cec42a6d5d"
      },
      "source": [
        "# get the dimensions\n",
        "print(\"Shape of training images:\",train_images.shape)\n",
        "print(\"Shape of training labels:\",train_labels.shape)\n",
        "print(\"unique labels:\",np.unique(train_labels))\n",
        "print(\"Shape of val images:\",val_images.shape)\n",
        "print(\"Shape of val labels:\",test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training images: (60000, 28, 28, 3)\n",
            "Shape of training labels: (60000,)\n",
            "unique labels: [0 1 2 3 4 5 6 7 8 9]\n",
            "Shape of val images: (2000, 28, 28, 3)\n",
            "Shape of val labels: (8000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP9IFITS7_oR"
      },
      "source": [
        "This is the random network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE88ltPfbyDR",
        "outputId": "71692b4b-9aa1-4fcd-d8d0-81bcef248d20"
      },
      "source": [
        "#normalising the mean and shifting by the mean\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "val_images = (val_images / 255) - 0.5\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28,28,3)))\n",
        "# model.add(layers.AveragePooling2D())\n",
        "\n",
        "# model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "# model.add(layers.AveragePooling2D())\n",
        "\n",
        "# model.add(layers.Flatten())\n",
        "\n",
        "# model.add(layers.Dense(units=120, activation='relu'))\n",
        "\n",
        "# model.add(layers.Dense(units=84, activation='relu'))\n",
        "\n",
        "# model.add(layers.Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "#lenet model\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28,28,3)))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "#adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "#sgd = optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "\n",
        "model.compile(\n",
        "  optimizer=adam,\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# obtain the summary\n",
        "#saved_model.summary()\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 5)\n",
        "mc = ModelCheckpoint('/content/gdrive/MyDrive/models/task2_mnist_3.h5', monitor='val_accuracy', mode='max', \n",
        "                     verbose=1, save_best_only=True)\n",
        "print(train_images.shape)\n",
        "print(val_images.shape)\n",
        "# Train the model.\n",
        "\n",
        "start_time = time.time()\n",
        "history=model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  validation_data=(val_images, to_categorical(val_labels)),  \n",
        "  epochs=5,\n",
        "  batch_size=32,\n",
        "  shuffle = True,\n",
        "  callbacks=[es,mc],\n",
        ")\n",
        "\n",
        "\n",
        "scores = model.evaluate(\n",
        "  test_images,\n",
        "  to_categorical(test_labels)\n",
        ")\n",
        "\n",
        "print('Test accuracy:', scores[1])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 3)\n",
            "(2000, 28, 28, 3)\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.4573 - accuracy: 0.8605 - val_loss: 0.0811 - val_accuracy: 0.9740\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.97400, saving model to /content/gdrive/MyDrive/models/task2_mnist_3.h5\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0658 - accuracy: 0.9792 - val_loss: 0.0610 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.97400 to 0.98000, saving model to /content/gdrive/MyDrive/models/task2_mnist_3.h5\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0458 - accuracy: 0.9858 - val_loss: 0.0752 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.98000\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.0437 - val_accuracy: 0.9850\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.98000 to 0.98500, saving model to /content/gdrive/MyDrive/models/task2_mnist_3.h5\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.0430 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.98500\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0314 - accuracy: 0.9887\n",
            "Test accuracy: 0.9887499809265137\n",
            "--- 129.0732717514038 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blRjE83yHRfY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W67ZrFK7lNY"
      },
      "source": [
        "This is the part of pretrained network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MRF8YSkaIhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa77a92e-a211-469a-c3a4-a178a8e7dc48"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 5)\n",
        "mc = ModelCheckpoint('/content/gdrive/MyDrive/models/pretrained_3_mnist.h5', monitor='val_accuracy', mode='max', \n",
        "                     verbose=1, save_best_only=True)\n",
        "saved_model=load_model(\"/content/gdrive/MyDrive/models/pretrained_3.h5\")\n",
        "start_time = time.time()\n",
        "\n",
        "history=saved_model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  validation_data=(val_images, to_categorical(val_labels)),  \n",
        "  epochs=5,\n",
        "  batch_size=32,\n",
        "  shuffle = True,\n",
        "  callbacks=[es,mc],\n",
        ")\n",
        "\n",
        "\n",
        "scores = saved_model.evaluate(\n",
        "  test_images,\n",
        "  to_categorical(test_labels)\n",
        ")\n",
        "\n",
        "print('Test accuracy:', scores[1])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2771 - accuracy: 0.9387 - val_loss: 0.1214 - val_accuracy: 0.9620\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.96200, saving model to /content/gdrive/MyDrive/models/pretrained_3_mnist.h5\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0830 - accuracy: 0.9744 - val_loss: 0.0825 - val_accuracy: 0.9760\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.96200 to 0.97600, saving model to /content/gdrive/MyDrive/models/pretrained_3_mnist.h5\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0626 - accuracy: 0.9817 - val_loss: 0.0735 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.97600 to 0.97750, saving model to /content/gdrive/MyDrive/models/pretrained_3_mnist.h5\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0503 - accuracy: 0.9844 - val_loss: 0.0525 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.97750 to 0.98400, saving model to /content/gdrive/MyDrive/models/pretrained_3_mnist.h5\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.0752 - val_accuracy: 0.9755\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.98400\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0461 - accuracy: 0.9861\n",
            "Test accuracy: 0.9861249923706055\n",
            "--- 128.09683299064636 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeHRHH1waIhN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp64VPEEGIA5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}