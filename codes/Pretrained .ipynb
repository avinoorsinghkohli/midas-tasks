{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pretrained.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf8YtiY44AaX",
        "outputId": "a36c9506-0d31-4188-d35b-8df23766e784"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he5jOWzE4JHm"
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "from PIL import Image \n",
        "from keras.datasets import mnist\n",
        "from keras import layers\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.utils import to_categorical\n",
        "from keras import initializers\n",
        "from keras import optimizers\n",
        "from matplotlib import pyplot\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from array import array\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxuk3mSb4J34"
      },
      "source": [
        "new_shape = (28,28)\n",
        "def load_images_from_folder(folder,images,y,i):\n",
        "  \n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename))\n",
        "        \n",
        "        #img = Image.open(os.path.join(folder,filename))\n",
        "        #print(type(img))\n",
        "        if img is not None:\n",
        "            #print(img.shape)\n",
        "            #plt.imshow(img)\n",
        "            img = cv2.resize(img,new_shape)\n",
        "            images.append(img) \n",
        "            \n",
        "            im=img.copy()\n",
        "            mean=0\n",
        "            st=0.7\n",
        "            gauss = np.random.normal(mean,st,im.shape)\n",
        "            gauss = gauss.astype('uint8')\n",
        "            im = cv2.add(im,gauss)\n",
        "            images.append(im)\n",
        "\n",
        "            ima=img.copy()\n",
        "            value = np.random.choice(np.array([-50, -40, -30, 30, 40, 50]))\n",
        "            hsv = cv2.cvtColor(ima, cv2.COLOR_BGR2HSV)\n",
        "            h, s, v = cv2.split(hsv)\n",
        "            if value >= 0:\n",
        "              lim = 255 - value\n",
        "              v[v > lim] = 255\n",
        "              v[v <= lim] += value\n",
        "            else:\n",
        "              lim = np.absolute(value)\n",
        "              v[v < lim] = 0\n",
        "              v[v >= lim] -= np.absolute(value)\n",
        "\n",
        "            final_hsv = cv2.merge((h, s, v))\n",
        "            ima = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "          \n",
        "            im1=img.copy()\n",
        "            value = np.random.choice(np.array([-50, -40, -30, 30, 40, 50]))\n",
        "            hsv = cv2.cvtColor(im1, cv2.COLOR_BGR2HSV)\n",
        "            h, s, v = cv2.split(hsv)\n",
        "            if value >= 0:\n",
        "              lim = 255 - value\n",
        "              s[s > lim] = 255\n",
        "              s[s <= lim] += value\n",
        "            else:\n",
        "              lim = np.absolute(value)\n",
        "              s[s < lim] = 0\n",
        "              s[s >= lim] -= np.absolute(value)\n",
        "\n",
        "            final_hsv = cv2.merge((h, s, v))\n",
        "            im1 = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "            im2=img.copy()\n",
        "            brightness = 10\n",
        "            contrast = random.randint(40, 100)\n",
        "            dummy = np.int16(im2)\n",
        "            dummy = dummy * (contrast/127+1) - contrast + brightness\n",
        "            dummy = np.clip(dummy, 0, 255)\n",
        "            im2 = np.uint8(dummy)\n",
        "            images.append(im2)\n",
        "\n",
        "            images.append(ima)\n",
        "            images.append(im1)\n",
        "            y.append(i-1)\n",
        "            y.append(i-1)\n",
        "            y.append(i-1)\n",
        "            y.append(i-1)\n",
        "            y.append(i-1)\n",
        "            #i=i+1\n",
        "    #print(i)\n",
        "    return images,y\n",
        "\n",
        "X = []\n",
        "y=[]\n",
        "for i in range(1,11):\n",
        "  #print(i)\n",
        "  if (i<10):\n",
        "    folder=\"/content/gdrive/MyDrive/trainPart1/train/Sample00\"+str(i)\n",
        "  else:\n",
        "    folder=\"/content/gdrive/MyDrive/trainPart1/train/Sample0\"+str(i)\n",
        "  X,y=load_images_from_folder(folder,X,y,i)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlGbS-_b4L9k",
        "outputId": "efa2a8b1-d6f0-45e0-8041-633c5592f2ce"
      },
      "source": [
        "X=np.array(X)\n",
        "print(X.shape)\n",
        "y=np.array(y)\n",
        "print(y.shape)\n",
        "train_images, test_imagesall, train_labels, test_labelsall = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "print('Shape of images is..',train_images.shape)\n",
        "print('Shape of labels is..',train_labels.shape)\n",
        "\n",
        "\n",
        "val_images = test_imagesall[0:200,:,:]\n",
        "val_labels = test_labelsall[0:200]\n",
        "test_images = test_imagesall[200:,:,:]\n",
        "test_labels = test_labelsall[200:]\n",
        "\n",
        "\n",
        "# display sample\n",
        "print(\"Shape of training images:\",train_images.shape)\n",
        "print(\"Shape of training labels:\",train_labels.shape)\n",
        "print(\"unique labels:\",np.unique(train_labels))\n",
        "print(\"Shape of val images:\",val_images.shape)\n",
        "print(\"Shape of val labels:\",val_labels.shape)\n",
        "print(\"Shape of test images:\",test_images.shape)\n",
        "print(\"Shape of test labels:\",test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 28, 28, 3)\n",
            "(2000,)\n",
            "Shape of images is.. (1700, 28, 28, 3)\n",
            "Shape of labels is.. (1700,)\n",
            "Shape of training images: (1700, 28, 28, 3)\n",
            "Shape of training labels: (1700,)\n",
            "unique labels: [0 1 2 3 4 5 6 7 8 9]\n",
            "Shape of val images: (200, 28, 28, 3)\n",
            "Shape of val labels: (200,)\n",
            "Shape of test images: (100, 28, 28, 3)\n",
            "Shape of test labels: (100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GDUaLeb4RUu",
        "outputId": "72cb9678-ac0b-4d08-e713-8421d0873dce"
      },
      "source": [
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "val_images = (val_images / 255) - 0.5\n",
        "print(train_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1700, 28, 28, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_4XQAHo4Yjv"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28,28,3)))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=10, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIuAjbex4jAS",
        "outputId": "7871ab0e-39ff-4030-e3dc-c66ec0d9cb79"
      },
      "source": [
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "\n",
        "model.compile(\n",
        "  optimizer=adam,\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# obtain the summary\n",
        "model.summary()\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 5)\n",
        "mc = ModelCheckpoint('/content/gdrive/MyDrive/models/pretrained_2.h5', monitor='val_accuracy', mode='max', \n",
        "                     verbose=1, save_best_only=True)\n",
        "print(train_images.shape)\n",
        "print(val_images.shape)\n",
        "# Train the model.\n",
        "\n",
        "\n",
        "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
        "\n",
        "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1)\n",
        "\n",
        "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
        "\n",
        "#Fitting the augmentation defined above to the data\n",
        "train_generator.fit(train_images)\n",
        "val_generator.fit(val_images)\n",
        "test_generator.fit(test_images)\n",
        "\n",
        "#AlexNet.fit_generator(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = val_generator.flow(x_val, y_val, batch_size=batch_size), validation_steps = 250, callbacks = [lrr], verbose=1)\n",
        "\n",
        "history=model.fit(train_generator.flow(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),batch_size=32),\n",
        "  validation_data=val_generator.flow(val_images, to_categorical(val_labels),batch_size=32),  \n",
        "  epochs=20,\n",
        "  shuffle = True,\n",
        "  callbacks=[es,mc],\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 6)         168       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 13, 13, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 16)        880       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               48120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 60,182\n",
            "Trainable params: 60,182\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(1700, 28, 28, 3)\n",
            "(200, 28, 28, 3)\n",
            "Epoch 1/20\n",
            "54/54 [==============================] - 4s 24ms/step - loss: 2.2888 - accuracy: 0.1144 - val_loss: 2.1212 - val_accuracy: 0.3400\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.34000, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 2/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 1.9262 - accuracy: 0.3394 - val_loss: 1.7364 - val_accuracy: 0.3750\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.34000 to 0.37500, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 3/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 1.5814 - accuracy: 0.4629 - val_loss: 1.5288 - val_accuracy: 0.4950\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.37500 to 0.49500, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 4/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 1.4812 - accuracy: 0.4913 - val_loss: 1.3248 - val_accuracy: 0.5800\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.49500 to 0.58000, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 5/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 1.2314 - accuracy: 0.5940 - val_loss: 1.2090 - val_accuracy: 0.6100\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.58000 to 0.61000, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 6/20\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.0927 - accuracy: 0.6348 - val_loss: 1.0584 - val_accuracy: 0.6500\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.61000 to 0.65000, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 7/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.9392 - accuracy: 0.6985 - val_loss: 0.9003 - val_accuracy: 0.7300\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.65000 to 0.73000, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 8/20\n",
            "54/54 [==============================] - 1s 14ms/step - loss: 0.7912 - accuracy: 0.7443 - val_loss: 0.8172 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.73000\n",
            "Epoch 9/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.6352 - accuracy: 0.7914 - val_loss: 0.7040 - val_accuracy: 0.7650\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.73000 to 0.76500, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 10/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.6111 - accuracy: 0.8058 - val_loss: 0.6251 - val_accuracy: 0.7850\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.76500 to 0.78500, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 11/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.5161 - accuracy: 0.8347 - val_loss: 0.4380 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.78500 to 0.86000, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 12/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.4489 - accuracy: 0.8513 - val_loss: 0.4423 - val_accuracy: 0.8650\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.86000 to 0.86500, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 13/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.4230 - accuracy: 0.8520 - val_loss: 0.3898 - val_accuracy: 0.8750\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.86500 to 0.87500, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 14/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.3709 - accuracy: 0.8760 - val_loss: 0.4024 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.87500\n",
            "Epoch 15/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.3479 - accuracy: 0.8892 - val_loss: 0.3253 - val_accuracy: 0.9100\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.87500 to 0.91000, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 16/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2638 - accuracy: 0.9173 - val_loss: 0.3238 - val_accuracy: 0.8900\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91000\n",
            "Epoch 17/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2660 - accuracy: 0.9174 - val_loss: 0.2355 - val_accuracy: 0.9450\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.91000 to 0.94500, saving model to /content/gdrive/MyDrive/models/pretrained_2.h5\n",
            "Epoch 18/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.1974 - accuracy: 0.9545 - val_loss: 0.2132 - val_accuracy: 0.9250\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.94500\n",
            "Epoch 19/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.1899 - accuracy: 0.9445 - val_loss: 0.2253 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.94500\n",
            "Epoch 20/20\n",
            "54/54 [==============================] - 1s 15ms/step - loss: 0.2123 - accuracy: 0.9316 - val_loss: 0.2011 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.94500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1TGMRPq4kGg",
        "outputId": "b047284e-2a5b-4e35-f708-556b52acc8dc"
      },
      "source": [
        "scores = model.evaluate(\n",
        "  test_images,\n",
        "  to_categorical(test_labels)\n",
        ")\n",
        "\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1265 - accuracy: 0.9600\n",
            "Test accuracy: 0.9599999785423279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktiz4EKyDf6i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}