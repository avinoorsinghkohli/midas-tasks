{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs1wJAhhhFGh",
        "outputId": "546612f4-1023-4620-c425-8485cbe1d4b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54QVpmsiXzSx"
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "from PIL import Image \n",
        "from keras.datasets import mnist\n",
        "from keras import layers\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.utils import to_categorical\n",
        "from keras import initializers\n",
        "from keras import optimizers\n",
        "from matplotlib import pyplot\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from array import array\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCle2sBV8YZ9"
      },
      "source": [
        "Preprocessing and Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehdV6ZvEuS4k"
      },
      "source": [
        "new_shape = (128,128)#reshaping of the images as the images were too large to give out any output\n",
        "def load_images_from_folder(folder,images,y,i):\n",
        "  \n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename))#stacking of the images in an array for train test split\n",
        "        \n",
        "        #img = Image.open(os.path.join(folder,filename))\n",
        "        #print(type(img))\n",
        "        if img is not None:\n",
        "            #print(img.shape)\n",
        "            #plt.imshow(img)\n",
        "            img = cv2.resize(img,new_shape)\n",
        "            \n",
        "            \n",
        "            im=img.copy() #adding the gaussian noise\n",
        "            mean=0\n",
        "            st=0.7\n",
        "            gauss = np.random.normal(mean,st,im.shape)\n",
        "            gauss = gauss.astype('uint8')\n",
        "            im = cv2.add(im,gauss)\n",
        "            \n",
        "\n",
        "            ima=img.copy() #adding the contrast \n",
        "            value = np.random.choice(np.array([-50, -40, -30, 30, 40, 50]))\n",
        "            hsv = cv2.cvtColor(ima, cv2.COLOR_BGR2HSV)\n",
        "            h, s, v = cv2.split(hsv)\n",
        "            if value >= 0:\n",
        "              lim = 255 - value\n",
        "              v[v > lim] = 255\n",
        "              v[v <= lim] += value\n",
        "            else:\n",
        "              lim = np.absolute(value)\n",
        "              v[v < lim] = 0\n",
        "              v[v >= lim] -= np.absolute(value)\n",
        "\n",
        "            final_hsv = cv2.merge((h, s, v))\n",
        "            ima = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "          \n",
        "            im1=img.copy()#adding the saturation\n",
        "            value = np.random.choice(np.array([-50, -40, -30, 30, 40, 50]))\n",
        "            hsv = cv2.cvtColor(im1, cv2.COLOR_BGR2HSV)\n",
        "            h, s, v = cv2.split(hsv)\n",
        "            if value >= 0:\n",
        "              lim = 255 - value\n",
        "              s[s > lim] = 255\n",
        "              s[s <= lim] += value\n",
        "            else:\n",
        "              lim = np.absolute(value)\n",
        "              s[s < lim] = 0\n",
        "              s[s >= lim] -= np.absolute(value)\n",
        "\n",
        "            final_hsv = cv2.merge((h, s, v))\n",
        "            im1 = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "            im2=img.copy()#altering the brightness\n",
        "            brightness = 10\n",
        "            contrast = random.randint(40, 100)\n",
        "            dummy = np.int16(im2)\n",
        "            dummy = dummy * (contrast/127+1) - contrast + brightness\n",
        "            dummy = np.clip(dummy, 0, 255)\n",
        "            im2 = np.uint8(dummy)\n",
        "\n",
        "            images.append(img)\n",
        "            images.append(im)\n",
        "            images.append(ima)\n",
        "            images.append(im1)\n",
        "            images.append(im2)\n",
        "            \n",
        "            y.append(i-1)\n",
        "            y.append(i-1)\n",
        "            y.append(i-1)\n",
        "            y.append(i-1)\n",
        "            y.append(i-1)\n",
        "            #i=i+1\n",
        "    #print(i)\n",
        "    return images,y\n",
        "\n",
        "X = []\n",
        "y=[]\n",
        "for i in range(1,63):#fetching the images from folder\n",
        "  #print(i)\n",
        "  if (i<10):\n",
        "    folder=\"/content/gdrive/MyDrive/trainPart1/train/Sample00\"+str(i)\n",
        "  else:\n",
        "    folder=\"/content/gdrive/MyDrive/trainPart1/train/Sample0\"+str(i)\n",
        "  X,y=load_images_from_folder(folder,X,y,i)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUg9ANjlYVFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac829ec-a6f4-4180-85b3-ae28ab9db905"
      },
      "source": [
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "val_images = (val_images / 255) - 0.5\n",
        "print(train_images.shape)\n",
        "# Flatten the images.\n",
        "\n",
        "\n",
        "#train_images = train_images.reshape((-1, 784,3))\n",
        "print(train_images.shape)\n",
        "#test_images = test_images.reshape((-1, 784,3))\n",
        "#val_images = val_images.reshape((-1, 784,3))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10540, 128, 128, 3)\n",
            "(10540, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdknuuOpYtE4"
      },
      "source": [
        "\n",
        "# # Build the model,inital model to just experiment\n",
        "# model = Sequential() # create model\n",
        "# model.add(Dense(64, input_dim=784, trainable=True,activation='relu', use_bias=True, \n",
        "#                 kernel_initializer=initializers.he_normal(seed=None))) # hidden \n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# model.add(Dense(64, use_bias=False))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation(\"relu\"))\n",
        "\n",
        "# model.add(Dense(62, trainable=True, activation='softmax')) # output layer\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(128,128,3)))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=62, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyNghnBOEr48"
      },
      "source": [
        "This is training block where hyperparameter tuning is required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7o2uSoS9Hbj"
      },
      "source": [
        "Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHP50EHwez3M",
        "outputId": "ae658f18-73f6-4ba4-b65f-4bd3dfab6b6a"
      },
      "source": [
        "\n",
        "scores = model.evaluate(\n",
        "  test_images,\n",
        "  to_categorical(test_labels)\n",
        ")\n",
        "\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 0s 6ms/step - loss: 0.1777 - accuracy: 0.9403\n",
            "Test accuracy: 0.9403409361839294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWzE4TYLaKLS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}