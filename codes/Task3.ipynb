{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErAANCZ1abbg",
        "outputId": "bf04ce1e-68dc-442f-bbae-518d714e9e91"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcHbTKPeamwi"
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import time\n",
        "from PIL import Image,ImageOps\n",
        "from keras.datasets import mnist\n",
        "\n",
        "from keras import layers\n",
        "import keras\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.utils import to_categorical\n",
        "from keras import initializers\n",
        "from keras import optimizers\n",
        "from matplotlib import pyplot\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from array import array\n",
        "import cv2\n",
        "import os\n",
        "import random\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrcunzC_anmm",
        "outputId": "1e12cd49-9ee5-45dd-d48b-8aaf824fce19"
      },
      "source": [
        "\n",
        "(train_imagesall, train_labels), (test_imagesall, test_labels) = mnist.load_data()\n",
        "\n",
        "np.random.shuffle(train_labels)\n",
        "\n",
        "\n",
        "train_imagesall=train_imagesall[:,:,:,np.newaxis]\n",
        "test_imagesall=test_imagesall[:,:,:,np.newaxis]\n",
        "train_images=([])\n",
        "test_images1=([])\n",
        "for i in range(0,60000):\n",
        "  train_images.append(np.concatenate((train_imagesall[i],train_imagesall[i],train_imagesall[i]),axis=2))\n",
        "for i in range(0,10000):\n",
        "  test_images1.append(np.concatenate((test_imagesall[i],test_imagesall[i],test_imagesall[i]),axis=2))\n",
        "\n",
        "train_images=np.array(train_images)\n",
        "test_images1=np.array(test_images1)\n",
        "\n",
        "\n",
        "val_images = test_images1[0:2000,:,:]\n",
        "val_labels = test_labels[0:2000]\n",
        "test_images = test_images1[2000:,:,:]\n",
        "test_labels = test_labels[2000:]\n",
        "\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "val_images = (val_images / 255) - 0.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg9OkG-Yannl",
        "outputId": "1edf8b8d-052b-4311-99f1-f4fe30076781"
      },
      "source": [
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28,28,3)))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "\n",
        "model.compile(\n",
        "  optimizer=adam,\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# obtain the summary\n",
        "#saved_model.summary()\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 5)\n",
        "mc = ModelCheckpoint('/content/gdrive/MyDrive/models/task3_random.h5', monitor='val_accuracy', mode='max', \n",
        "                     verbose=1, save_best_only=True)\n",
        "\n",
        "# Train the model.\n",
        "\n",
        "start_time = time.time()\n",
        "history=model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  validation_data=(val_images, to_categorical(val_labels)),  \n",
        "  epochs=5,\n",
        "  batch_size=32,\n",
        "  shuffle = True,\n",
        "  callbacks=[es,mc],\n",
        ")\n",
        "\n",
        "\n",
        "scores = model.evaluate(\n",
        "  test_images,\n",
        "  to_categorical(test_labels)\n",
        ")\n",
        "\n",
        "print('Test accuracy:', scores[1])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
        "mc = ModelCheckpoint(r'/content/gdrive/MyDrive/models/task3_pretrained.h5', monitor='val_accuracy', mode='max', \n",
        "                     verbose=1, save_best_only=True)\n",
        "saved_model=load_model(\"/content/gdrive/MyDrive/models/pretrained_2.h5\")\n",
        "start_time = time.time()\n",
        "\n",
        "history=saved_model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  validation_data=(val_images, to_categorical(val_labels)),  \n",
        "  epochs=5,\n",
        "  batch_size=32,\n",
        "  shuffle = True,\n",
        "  callbacks=[es,mc],\n",
        ")\n",
        "\n",
        "\n",
        "scores = saved_model.evaluate(\n",
        "  test_images,\n",
        "  to_categorical(test_labels)\n",
        ")\n",
        "\n",
        "print('Test accuracy:', scores[1])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 2.3023 - accuracy: 0.1078 - val_loss: 2.3009 - val_accuracy: 0.1170\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11700, saving model to /content/gdrive/MyDrive/models/task3_random.h5\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 2.3014 - accuracy: 0.1141 - val_loss: 2.3013 - val_accuracy: 0.1170\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.11700\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 2.3015 - accuracy: 0.1100 - val_loss: 2.3006 - val_accuracy: 0.1170\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.11700\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 2.3015 - accuracy: 0.1121 - val_loss: 2.3032 - val_accuracy: 0.1170\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.11700\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 2.3010 - accuracy: 0.1106 - val_loss: 2.3030 - val_accuracy: 0.1170\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.11700\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 2.3042 - accuracy: 0.1126\n",
            "Test accuracy: 0.11262500286102295\n",
            "--- 133.8827748298645 seconds ---\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 2.4031 - accuracy: 0.1048 - val_loss: 2.2973 - val_accuracy: 0.1520\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.15200, saving model to /content/gdrive/MyDrive/models/task3_pretrained.h5\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 2.3017 - accuracy: 0.1125 - val_loss: 2.3006 - val_accuracy: 0.1170\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.15200\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 2.3015 - accuracy: 0.1123 - val_loss: 2.3013 - val_accuracy: 0.1170\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.15200\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1170\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.15200\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3004 - val_accuracy: 0.1170\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.15200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 2.3011 - accuracy: 0.1126\n",
            "Test accuracy: 0.11262500286102295\n",
            "--- 132.3210735321045 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYEKR1Mh34oX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0PrN6mRwBqr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}